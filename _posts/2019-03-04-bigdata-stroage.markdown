---
layout: post
title:  "如何构建数据平台的存储"
date:   2019-03-09 00:18:23 +0700
categories: [bigdata]
---

#### 概述
  数据平台，存储是不可以少的一部分，同时存储也是极其重要的一部分，存储是整个平台的一个底子。如何构建数据平台的存储部分，今天我们重点讨论一下这块。
通常我们一说存储这块大家可能想到就是HDFS,因为大家一说数据就会想到Hadoop,而Hadoop的分布式文件存储就是HDFS.但是随着云厂商的出现我们
会接触到更多的存储，如AWS 的S3 ,阿里的OSS等。

#### 数据平台的存储  
  我们知道在大数据中有一个概念就是程序跟着数据跑，为什么有这个概念。是因为数据在网络传输过程中花费较多的时间，而程序本部是很少的，将程序
分发到数据的机器上进行计算该节点上面的数据，输出中间结果，然后再将相关数据进汇集从而加快整个计算过程。这里面我们就可以得出两个概念一个TaskNode,一个是DataNode
DataNode就是我们存储数据的节点。接下来我们先重点介绍一下HDFS
  HDFS（Hadoop Distributed File System）是Hadoop项目的核心子项目，是分布式计算中数据存储管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的，可以运行于廉价的商用服务器上。它所具有的高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征为海量数据提供了不怕故障的存储，为超大数据集（Large Data Set）的应用处理带来了很多便利。
HDFS 源于 Google 在2003年10月份发表的GFS（Google File System） 论文。 它其实就是 GFS 的一个克隆版本。  
  之所以选择 HDFS 存储数据，因为 HDFS 具有以下优点：
  1.高容错性  
  > 数据自动保存多个副本。它通过增加副本的形式，提高容错性。  
  > 某一个副本丢失以后，它可以自动恢复，这是由 HDFS 内部机制实现的，我们不必关心。  
  
  2.适合批处理  
  > 它是通过移动计算而不是移动数据。  
  > 它会把数据位置暴露给计算框架。
  
  3.适合大数据处理  
  > 处理数据达到 GB、TB、甚至PB级别的数据。  
  > 能够处理百万规模以上的文件数量，数量相当之大。  
  > 能够处理10K节点的规模。  
  
  4.流式文件访问  
  > 一次写入，多次读取。文件一旦写入不能修改，只能追加。  
  > 它能保证数据的一致性。  
  
  5.可构建在廉价机器上(运维成本高)  
  > 它通过多副本机制，提高可靠性。  
  > 它提供了容错和恢复机制。比如某一个副本丢失，可以通过其它副本来恢复。  
 
  
  当然 HDFS 也有它的劣势，并不适合所有的场合：  
  1.低延时数据访问  
  > 比如毫秒级的来存储数据，这是不行的，它做不到。  
  > 它适合高吞吐率的场景，就是在某一时间内写入大量的数据。但是它在低延时的情况下是不行的，比如毫秒级以内读取数据，这样它是很难做到的。  
  
  2.小文件存储  
  > 存储大量小文件(这里的小文件是指小于HDFS系统的Block大小的文件（默认64M）)的话，它会占用 NameNode大量的内存来存储文件、目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。  
  > 小文件存储的寻道时间会超过读取时间，它违反了HDFS的设计目标.  
  
  3.并发写入、文件随机修改  
  > 一个文件只能有一个写，不允许多个线程同时写。  
  > 仅支持数据 append（追加），不支持文件的随机修改。  
  
  
  接下面我们讲一下HDFS这个原理部分：
  
  
  
  
#### 相对于HDFS各云厂家的存储是怎样的  